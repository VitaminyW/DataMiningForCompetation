{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\学习\\微热点大赛\\DataMiningForCompetation')\n",
    "from db import MyDB\n",
    "#加载数据库\n",
    "db = MyDB(host='182.61.54.181', user='root', password='yW88224646!', db='WRD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#加载使用库\n",
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import threading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def saveTempFile(path,Object_):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(Object_,f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# [是否为默认文本,内容文本,内容表情,地域,城市,性别,粉丝数,微博数,转,评,赞,话题,微博情绪,精准地域,中图地址,\n",
    "# MD5-作者ID,MD5-mid,MD5-根微博mid,MD5-根微博用户UID,MD5-父微博ID,MD5-父微博用户ID]\n",
    "targetRoot = r'E:\\Download\\数据大赛\\选题1\\初步分词\\\\'\n",
    "sourceRoot = r'E:\\Download\\数据大赛\\选题1\\微博'\n",
    "needPartOfSpeech = ['a','ad','an']\n",
    "tl1 = []\n",
    "emotion = re.compile(r'(\\[.*?\\])')\n",
    "tag = re.compile(r'(#.*?#)')\n",
    "tags = []\n",
    "emotions = []\n",
    "files = None\n",
    "for root,dirs,fs in os.walk(sourceRoot):\n",
    "    files = fs\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    fileAbsolutePath = sourceRoot+'\\\\'+file\n",
    "    dataFile = pandas.read_csv(fileAbsolutePath,encoding='gb18030')\n",
    "    tempList = []\n",
    "    for item in tqdm(dataFile.values):\n",
    "        temp = [int(item[0] == '转发微博 '),json.dumps(emotion.findall(item[0])), json.dumps(tag.findall(item[0])), item[0]]\n",
    "        for e in temp[1]:\n",
    "            temp[3] = temp[3].replace(e,'')\n",
    "        for t in temp[2]:\n",
    "            temp[3] = temp[3].replace(t,'')\n",
    "        if temp[3] == '转发微博 ':\n",
    "            temp[3] = ''\n",
    "        tempWords = []\n",
    "        words = pseg.cut(temp[3],use_paddle=True)\n",
    "        for word, flag in words:\n",
    "            if flag in needPartOfSpeech:\n",
    "                tempWords.append(word)\n",
    "        temp[3] = json.dumps(tempWords)\n",
    "        temp.append(int(item[1] == '敏感'))\n",
    "        temp.append(int(item[2] == '原创'))\n",
    "        for i in range(3,25):\n",
    "            if i == 9 or i == 4:\n",
    "                continue\n",
    "            temp.append(item[i])\n",
    "        tempList.append(temp)\n",
    "    tempList = pandas.DataFrame(tempList)\n",
    "    tempList.columns = ['是否为默认文本','内容表情','内容标签','过滤后内容分词json串','是否敏感','是否原创','发布日期','认证类型','地域','城市','性别','粉丝数','微博数','转','评','赞','话题','微博情绪','精准地域','中图地址',\n",
    "      'MD5-作者ID','MD5-mid','MD5-根微博mid','MD5-根微博用户UID','MD5-父微博ID','MD5-父微博用户ID']\n",
    "    tempList.to_csv(targetRoot+file,encoding='gb18030')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#读取一个csv文件进行分词结果分析\n",
    "test = pandas.read_csv(r'E:\\Download\\数据大赛\\选题1\\初步分词\\《乘风破浪的姐姐》成团之夜-2.csv',encoding='gb18030')\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    test.loc[i:i,'过滤后内容分词json串'] = str(json.loads(test['过滤后内容分词json串'][i]))\n",
    "test.to_csv(r'E:\\Download\\数据大赛\\选题1\\初步分词\\test.csv',encoding='gb18030')\n",
    "#第一部分尝试感受：目前最需要的应该是构建词表，反而不需要太过在意数据的其他属性"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [01:38<00:00,  5.19s/it]\n"
     ]
    }
   ],
   "source": [
    "#第二部分尝试将使用进行二分类数据预处理\n",
    "#1. 遍历数据，得到微博情绪的种类\n",
    "sourceRoot = r'E:\\Download\\数据大赛\\选题1\\微博'\n",
    "files = None\n",
    "WBEmotionList = list()\n",
    "for root,dirs,fs in os.walk(sourceRoot):\n",
    "    files = fs\n",
    "    break\n",
    "for file in tqdm(files):\n",
    "    fileAbsolutePath = sourceRoot+'\\\\'+file\n",
    "    dataFile = pandas.read_csv(fileAbsolutePath,encoding='gb18030')\n",
    "    WBEmotionList.extend(list(set(dataFile['微博情绪'].values.tolist())))\n",
    "WBEmotionList = list(set(WBEmotionList))\n",
    "saveTempFile(r'E:\\Download\\数据大赛\\选题1\\temp\\WBEmotionList.json',WBEmotionList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "emotionsToThereEmotions = {'愤怒':'negative','恐惧':'negative','悲伤':'negative','中性':'neutral','喜悦':'positive','惊奇':'positive'}\n",
    "position = 0 #临界资源\n",
    "#定义线程工作\n",
    "max_Threading = 9\n",
    "threadLock = threading.Lock()\n",
    "\n",
    "def getNewFileName():\n",
    "    global position\n",
    "    fileName = files[position]\n",
    "    if position < 19:\n",
    "        position += 1\n",
    "        return fileName\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def workFunction(id):\n",
    "    nowFileName = None\n",
    "    emotion = re.compile(r'(\\[.*?\\])')\n",
    "    tag = re.compile(r'(#.*?#)')\n",
    "    while True:\n",
    "        threadLock.acquire()\n",
    "        nowFileName = getNewFileName()\n",
    "        threadLock.release()\n",
    "        print(nowFileName)\n",
    "        if nowFileName is None :\n",
    "            break\n",
    "        words = {'negative':[],'neutral':[],'positive':[]}\n",
    "        tempFile = pandas.read_csv(sourceRoot+'\\\\'+nowFileName,encoding='gb18030')\n",
    "        total = tempFile.shape[0]\n",
    "        for index,item in enumerate(tempFile.values.tolist()):\n",
    "           # if (index%1000) == 0:\n",
    "               # print(index/total)\n",
    "            oneSentenceWords = []\n",
    "            if item[0] == '转发微博 ':\n",
    "                oneSentenceWords.append('转发微博 ')\n",
    "                item[0].replace('转发微博 ','')\n",
    "            for e in emotion.findall(item[0]):\n",
    "                oneSentenceWords.append(e)\n",
    "                item[0].replace(e,'')\n",
    "            for t in tag.findall(item[0]):\n",
    "                oneSentenceWords.append(t)\n",
    "                item[0].replace(t,'')\n",
    "            w = pseg.cut(item[0],use_paddle=True)\n",
    "            for wd, fg in w:\n",
    "                oneSentenceWords.append(wd)\n",
    "            for j in oneSentenceWords:#将所有词记录进结构中\n",
    "                words[emotionsToThereEmotions[item[16]]].append(j)\n",
    "            if int((index/total)%(0.01*total)) == 0:#记录当前状态\n",
    "                with open(r'E:\\Download\\数据大赛\\选题1\\temp'+'\\\\'+nowFileName+'.txt','a+') as f:\n",
    "                    f.write(str((index/total))+'\\n')\n",
    "        with open(r'E:\\Download\\数据大赛\\选题1\\第二部分分词\\%d.txt'%id,'a+') as f:\n",
    "            for key in words:\n",
    "                for wd in words[key]:\n",
    "                    f.write(wd+'\\t'+key+'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020天猫双11总成交额4982亿元.csv\n",
      "3人伪造老干妈印章与腾讯签合同被刑拘.csv\n",
      "《乘风破浪的姐姐》成团之夜-1.csv\n",
      "《乘风破浪的姐姐》成团之夜-2.csv\n",
      "《网络直播营销活动行为规范》7月1日实施.csv\n",
      "上海首个小区停用丰巢快递柜.csv\n",
      "冒名顶替上大学拟写入刑法.csv\n",
      "司机为救婴儿连闯红灯家属拒绝作证.csv\n",
      "周杰伦王俊凯成为英雄联盟代言人-1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\17797\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.838 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "for i in range(max_Threading):\n",
    "    threads.append(threading.Thread(target=workFunction,args=[i]))\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}